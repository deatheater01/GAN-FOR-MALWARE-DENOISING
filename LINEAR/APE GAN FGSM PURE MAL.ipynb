{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING\n"
     ]
    }
   ],
   "source": [
    "print(\"STARTING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils  # utilities for one-hot encoding of ground truth values\n",
    "\n",
    "import os\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Sequential  # basic class for specifying and training a neural network\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose, Dense, Activation, Flatten, LeakyReLU, BatchNormalization, ZeroPadding2D, Conv1D\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TEST = np.load('./DATA/X_CLEAN_ONLY_MAL.npy')\n",
    "Y_TEST = np.load('./DATA/X_LABEL_ONLY_MAL.npy')\n",
    "coeff = np.load('./DATA/ORIGINAL/coeff_features.npy')\n",
    "X_N_TEST = np.load('./DATA/X_ADV_ONLY_MAL.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Import and test\n",
    "\n",
    "Building a classifier to evaluate the denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1]), array([3799], dtype=int64))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_TEST,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Pitch\\.conda\\envs\\tf1-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\Pitch\\.conda\\envs\\tf1-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Pitch\\.conda\\envs\\tf1-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 2948)              8693652   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               377472    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 9,071,253\n",
      "Trainable params: 9,071,253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelClassifier = keras.models.load_model('./modelClassifierFGSM.h5')\n",
    "modelClassifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3799/3799 [==============================] - 2s 556us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04282340146973827, 1.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelClassifier.evaluate(X_TEST, Y_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3799/3799 [==============================] - 2s 450us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[299.8835265824091, 0.0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelClassifier.evaluate(X_N_TEST, Y_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of classifier\n",
    "\n",
    "- Clean data = 100%\n",
    "- FGSM attacked data = 0%\n",
    "\n",
    "But remeber this is just malware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2948,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weightsmodelClassifier, biasesmodelClassifier = modelClassifier.layers[0].get_weights()\n",
    "modelClassifier.layers[0].get_weights()[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ben and Mal Cols and Pure Malware and Benign Arrays\n",
    "\n",
    "Pure Malware = all malware columns will be one\n",
    "\n",
    "Pure Ben = all Ben cols will be one\n",
    "\n",
    "This gives us the 2 extreme cases to compare with one another during GAN training. All Ben being the most benign and all mal being the worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1513 1435\n"
     ]
    }
   ],
   "source": [
    "mal_col_index = []\n",
    "ben_col_index = []\n",
    "for i in range(len(coeff)):\n",
    "    if coeff[i] > 0:\n",
    "        mal_col_index.append(i)\n",
    "    elif coeff[i] < 0:\n",
    "        ben_col_index.append(i)\n",
    "    else:\n",
    "        print(\"DANGER\")\n",
    "print(len(mal_col_index),len(ben_col_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([1513, 1435], dtype=int64))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_BEN_APK = np.zeros(X_TEST[0].shape)\n",
    "for i in ben_col_index:\n",
    "    ALL_BEN_APK[i] = 1\n",
    "np.unique(ALL_BEN_APK,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([1435, 1513], dtype=int64))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_MAL_APK = np.zeros(X_TEST[0].shape)\n",
    "for i in mal_col_index:\n",
    "    ALL_MAL_APK[i] = 1\n",
    "np.unique(ALL_MAL_APK,return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APE GAN DEF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MANHATTAN(y_true, y_pred):\n",
    "    return K.sum( K.abs( y_true - y_pred),axis=1,keepdims=True) + 1e-10\n",
    "\n",
    "def SRMSE(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1) + 1e-10)\n",
    "\n",
    "def WMOD(y_true, y_pred):\n",
    "    return K.abs(1 - K.mean(y_true * y_pred))\n",
    "\n",
    "def WGAN(y_true, y_pred):\n",
    "    return K.abs(K.mean(y_true * y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(input_dims):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape = input_dims, activation='relu'))\n",
    "    #model.add(Dense(2048, input_shape = input_dims, activation='relu'))\n",
    "    #model.add(Dense(1024, activation='relu'))\n",
    "    #model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dense(2, activation='relu'))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.add(Activation('tanh'))\n",
    "    return model\n",
    "\n",
    "def discriminator(input_dims):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape = input_dims, activation='relu'))\n",
    "    #model.add(Dense(2048, input_shape = input_dims, activation='relu'))\n",
    "    #model.add(Dense(1024, activation='relu'))\n",
    "    #model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dense(2, activation='relu'))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    return model\n",
    "\n",
    "def APEGAN(input_dims):\n",
    "    G = generator(input_dims)\n",
    "    print(\"========================\\n\\nGENERATOR\\n\\n\")\n",
    "    print(G.summary())\n",
    "    print(\"==============\\n\\n\")\n",
    "    \n",
    "    D = discriminator(input_dims)\n",
    "    print(\"========================\\n\\nDISCRIMINATOR\\n\\n\")\n",
    "    print(D.summary())\n",
    "    print(\"==============\\n\\n\")\n",
    "    \n",
    "    ipt = Input(input_dims)\n",
    "    print(\"========================\\n\\nINPUT TENSOR\\n\\n\")\n",
    "    print(ipt)\n",
    "    print(\"==============\\n\\n\")\n",
    "    \n",
    "    purified = G(ipt)\n",
    "    print(\"========================\\n\\nPURIFIED TENSOR\\n\\n\")\n",
    "    print(purified)\n",
    "    print(\"==============\\n\\n\")\n",
    "    \n",
    "    D.trainable = False\n",
    "    \n",
    "    judge = D(purified)\n",
    "    print(\"========================\\n\\nJUDGE TENSOR\\n\\n\")\n",
    "    print(judge)\n",
    "    print(\"==============\\n\\n\")\n",
    "    \n",
    "    GAN = Model(ipt, [judge,purified])\n",
    "    print(\"========================\\n\\nGAN BASIC\\n\\n\")\n",
    "    print(GAN.summary())\n",
    "    print(\"==============\\n\\n\")\n",
    "    \n",
    "    GAN.compile(optimizer='adam',\n",
    "                loss=['binary_crossentropy',WGAN],\n",
    "                loss_weights=[0.02, 0.9])\n",
    "    \n",
    "    print(\"========================\\n\\nGAN AFTER COMPILE\\n\\n\")\n",
    "    print(GAN.summary())\n",
    "    print(\"==============\\n\\n\")\n",
    "    \n",
    "    return GAN,G,D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APE GAN RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10 # original 500\n",
    "batch_size=128\n",
    "\n",
    "N = X_TEST.shape[0]\n",
    "x_clean = X_TEST.copy()\n",
    "x_adv = X_N_TEST.copy()\n",
    "x_label = Y_TEST.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "\n",
      "GENERATOR\n",
      "\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1, 2948, 512)      1024      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1, 2948, 256)      131328    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1, 2948, 128)      32896     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1, 2948, 64)       8256      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1, 2948, 32)       2080      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1, 2948, 16)       528       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1, 2948, 8)        136       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1, 2948, 4)        36        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1, 2948, 2)        10        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1, 2948, 1)        3         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1, 2948, 1)        0         \n",
      "=================================================================\n",
      "Total params: 176,297\n",
      "Trainable params: 176,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "==============\n",
      "\n",
      "\n",
      "========================\n",
      "\n",
      "DISCRIMINATOR\n",
      "\n",
      "\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 1, 2948, 512)      1024      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1, 2948, 256)      131328    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1, 2948, 128)      32896     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1, 2948, 64)       8256      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1, 2948, 32)       2080      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1, 2948, 16)       528       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1, 2948, 8)        136       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1, 2948, 4)        36        \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1, 2948, 2)        10        \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1, 2948, 1)        3         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1, 2948, 1)        0         \n",
      "=================================================================\n",
      "Total params: 176,297\n",
      "Trainable params: 176,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "==============\n",
      "\n",
      "\n",
      "========================\n",
      "\n",
      "INPUT TENSOR\n",
      "\n",
      "\n",
      "Tensor(\"input_1:0\", shape=(?, 1, 2948, 1), dtype=float32)\n",
      "==============\n",
      "\n",
      "\n",
      "========================\n",
      "\n",
      "PURIFIED TENSOR\n",
      "\n",
      "\n",
      "Tensor(\"sequential_1/activation_1/Tanh:0\", shape=(?, 1, 2948, 1), dtype=float32)\n",
      "==============\n",
      "\n",
      "\n",
      "========================\n",
      "\n",
      "JUDGE TENSOR\n",
      "\n",
      "\n",
      "Tensor(\"sequential_2/activation_2/Sigmoid:0\", shape=(?, 1, 2948, 1), dtype=float32)\n",
      "==============\n",
      "\n",
      "\n",
      "========================\n",
      "\n",
      "GAN BASIC\n",
      "\n",
      "\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1, 2948, 1)        0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1, 2948, 1)        176297    \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 1, 2948, 1)        176297    \n",
      "=================================================================\n",
      "Total params: 352,594\n",
      "Trainable params: 176,297\n",
      "Non-trainable params: 176,297\n",
      "_________________________________________________________________\n",
      "None\n",
      "==============\n",
      "\n",
      "\n",
      "========================\n",
      "\n",
      "GAN AFTER COMPILE\n",
      "\n",
      "\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1, 2948, 1)        0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1, 2948, 1)        176297    \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 1, 2948, 1)        176297    \n",
      "=================================================================\n",
      "Total params: 352,594\n",
      "Trainable params: 176,297\n",
      "Non-trainable params: 176,297\n",
      "_________________________________________________________________\n",
      "None\n",
      "==============\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GAN, G, D = APEGAN([1,X_TEST.shape[1],1])\n",
    "# GAN,G,D = APEGAN([X_TEST.shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "EPOCH 0 \n",
      "\n",
      "\n",
      "=====\n",
      "SHAPE of XCLEAN\n",
      "(128, 1, 2948, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pitch\\.conda\\envs\\tf1-gpu\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====\n",
      "NP ONES TRAIN ON BATCH DISCRIMINATOR\n",
      "1 [0.34657296538352966, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pitch\\.conda\\envs\\tf1-gpu\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====\n",
      "NP ZEROS TRAIN ON BATCH DISCRIMINATOR\n",
      "2 [0.6931459307670593, 0, 0]\n",
      "\n",
      "=====\n",
      "LOSS HISTORY\n",
      "[[0.6931459307670593, 0.69314593, 0.0], 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "=====\n",
      "TRAIN ON BATCH GAN\n",
      "Epoch number: 0 ; Loss [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      " EPOCHING \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "EPOCH 1 \n",
      "\n",
      "\n",
      "=====\n",
      "SHAPE of XCLEAN\n",
      "(128, 1, 2948, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pitch\\.conda\\envs\\tf1-gpu\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====\n",
      "NP ONES TRAIN ON BATCH DISCRIMINATOR\n",
      "1 [0.34657296538352966, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "NP ZEROS TRAIN ON BATCH DISCRIMINATOR\n",
      "2 [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "LOSS HISTORY\n",
      "[[0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "=====\n",
      "TRAIN ON BATCH GAN\n",
      "Epoch number: 1 ; Loss [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      " EPOCHING \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "EPOCH 2 \n",
      "\n",
      "\n",
      "=====\n",
      "SHAPE of XCLEAN\n",
      "(128, 1, 2948, 1)\n",
      "\n",
      "=====\n",
      "NP ONES TRAIN ON BATCH DISCRIMINATOR\n",
      "1 [0.34657296538352966, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "NP ZEROS TRAIN ON BATCH DISCRIMINATOR\n",
      "2 [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "LOSS HISTORY\n",
      "[[0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "=====\n",
      "TRAIN ON BATCH GAN\n",
      "Epoch number: 2 ; Loss [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      " EPOCHING \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "EPOCH 3 \n",
      "\n",
      "\n",
      "=====\n",
      "SHAPE of XCLEAN\n",
      "(128, 1, 2948, 1)\n",
      "\n",
      "=====\n",
      "NP ONES TRAIN ON BATCH DISCRIMINATOR\n",
      "1 [0.34657296538352966, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "NP ZEROS TRAIN ON BATCH DISCRIMINATOR\n",
      "2 [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "LOSS HISTORY\n",
      "[[0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "=====\n",
      "TRAIN ON BATCH GAN\n",
      "Epoch number: 3 ; Loss [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      " EPOCHING \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "EPOCH 4 \n",
      "\n",
      "\n",
      "=====\n",
      "SHAPE of XCLEAN\n",
      "(128, 1, 2948, 1)\n",
      "\n",
      "=====\n",
      "NP ONES TRAIN ON BATCH DISCRIMINATOR\n",
      "1 [0.34657296538352966, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "NP ZEROS TRAIN ON BATCH DISCRIMINATOR\n",
      "2 [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "LOSS HISTORY\n",
      "[[0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], 0, 0, 0, 0, 0]\n",
      "\n",
      "=====\n",
      "TRAIN ON BATCH GAN\n",
      "Epoch number: 4 ; Loss [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      " EPOCHING \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "EPOCH 5 \n",
      "\n",
      "\n",
      "=====\n",
      "SHAPE of XCLEAN\n",
      "(128, 1, 2948, 1)\n",
      "\n",
      "=====\n",
      "NP ONES TRAIN ON BATCH DISCRIMINATOR\n",
      "1 [0.34657296538352966, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "NP ZEROS TRAIN ON BATCH DISCRIMINATOR\n",
      "2 [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "LOSS HISTORY\n",
      "[[0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], 0, 0, 0, 0]\n",
      "\n",
      "=====\n",
      "TRAIN ON BATCH GAN\n",
      "Epoch number: 5 ; Loss [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      " EPOCHING \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "EPOCH 6 \n",
      "\n",
      "\n",
      "=====\n",
      "SHAPE of XCLEAN\n",
      "(128, 1, 2948, 1)\n",
      "\n",
      "=====\n",
      "NP ONES TRAIN ON BATCH DISCRIMINATOR\n",
      "1 [0.34657296538352966, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "NP ZEROS TRAIN ON BATCH DISCRIMINATOR\n",
      "2 [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "LOSS HISTORY\n",
      "[[0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], 0, 0, 0]\n",
      "\n",
      "=====\n",
      "TRAIN ON BATCH GAN\n",
      "Epoch number: 6 ; Loss [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      " EPOCHING \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "EPOCH 7 \n",
      "\n",
      "\n",
      "=====\n",
      "SHAPE of XCLEAN\n",
      "(128, 1, 2948, 1)\n",
      "\n",
      "=====\n",
      "NP ONES TRAIN ON BATCH DISCRIMINATOR\n",
      "1 [0.34657296538352966, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "NP ZEROS TRAIN ON BATCH DISCRIMINATOR\n",
      "2 [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "LOSS HISTORY\n",
      "[[0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], 0, 0]\n",
      "\n",
      "=====\n",
      "TRAIN ON BATCH GAN\n",
      "Epoch number: 7 ; Loss [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      " EPOCHING \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "EPOCH 8 \n",
      "\n",
      "\n",
      "=====\n",
      "SHAPE of XCLEAN\n",
      "(128, 1, 2948, 1)\n",
      "\n",
      "=====\n",
      "NP ONES TRAIN ON BATCH DISCRIMINATOR\n",
      "1 [0.34657296538352966, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "NP ZEROS TRAIN ON BATCH DISCRIMINATOR\n",
      "2 [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "LOSS HISTORY\n",
      "[[0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], 0]\n",
      "\n",
      "=====\n",
      "TRAIN ON BATCH GAN\n",
      "Epoch number: 8 ; Loss [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      " EPOCHING \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "EPOCH 9 \n",
      "\n",
      "\n",
      "=====\n",
      "SHAPE of XCLEAN\n",
      "(128, 1, 2948, 1)\n",
      "\n",
      "=====\n",
      "NP ONES TRAIN ON BATCH DISCRIMINATOR\n",
      "1 [0.34657296538352966, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "NP ZEROS TRAIN ON BATCH DISCRIMINATOR\n",
      "2 [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "LOSS HISTORY\n",
      "[[0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0]]\n",
      "\n",
      "=====\n",
      "TRAIN ON BATCH GAN\n",
      "Epoch number: 9 ; Loss [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      " EPOCHING \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scalarloss = [0,0,0]\n",
    "LossHistory = [0]*epochs\n",
    "for cur_epoch in range(epochs):\n",
    "    \n",
    "    print(\"\\n\\nEPOCH\",cur_epoch,\"\\n\")\n",
    "    \n",
    "    idx = np.random.randint(0, N*4//5, size=batch_size)\n",
    "    x_clean_batch = x_clean[idx,].reshape(-1,1,2948,1)\n",
    "    x_adv_batch = x_adv[idx,].reshape(-1,1,2948,1)\n",
    "    \n",
    "    ALL_MAL_APK_BATCH = np.tile(ALL_MAL_APK,(batch_size,1))\n",
    "    ALL_BEN_APK_BATCH = np.tile(ALL_BEN_APK,(batch_size,1))    \n",
    "    \n",
    "    print(\"\\n=====\\nSHAPE of XCLEAN\")\n",
    "    print(x_clean_batch.shape)\n",
    "    \n",
    "    scalarloss[0] = D.train_on_batch(x_clean_batch, ALL_MAL_APK_BATCH.reshape(-1,1,2948,1))/2\n",
    "    \n",
    "    print(\"\\n=====\\nNP ONES TRAIN ON BATCH DISCRIMINATOR\")\n",
    "    print(\"1 \"+str(scalarloss))\n",
    "    \n",
    "    scalarloss[0] += D.train_on_batch(x_adv_batch, ALL_BEN_APK_BATCH.reshape(-1,1,2948,1))/2\n",
    "    \n",
    "    print(\"\\n=====\\nNP ZEROS TRAIN ON BATCH DISCRIMINATOR\")\n",
    "    print(\"2 \"+str(scalarloss))\n",
    "    \n",
    "    GAN.train_on_batch(x_adv_batch, [ ALL_MAL_APK_BATCH.reshape(-1,1,2948,1), x_clean_batch])\n",
    "    \n",
    "    scalarloss[1:] = GAN.train_on_batch(x_adv_batch, [ ALL_MAL_APK_BATCH.reshape(-1,1,2948,1), x_clean_batch])[1:]\n",
    "    \n",
    "#     LossHistory.append(scalarloss)\n",
    "    LossHistory[cur_epoch] = scalarloss\n",
    "    print(\"\\n=====\\nLOSS HISTORY\")\n",
    "    print(LossHistory)\n",
    "    \n",
    "    print(\"\\n=====\\nTRAIN ON BATCH GAN\")\n",
    "    print(\"Epoch number:\",cur_epoch,\"; Loss\",scalarloss)\n",
    "    print(\"\\n EPOCHING \\n\\n\\n\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "We use the Generator of the trained APEGAN to purify data samples and then test it out with the trained classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "\n",
      "KERAS LOAD MODEL\n",
      "\n",
      "\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 2948)              8693652   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               377472    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 9,071,253\n",
      "Trainable params: 9,071,253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "==============\n",
      "\n",
      "\n",
      "========================\n",
      "\n",
      "CLEAN\n",
      "\n",
      "\n",
      "[[[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [1.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]]\n",
      "==============\n",
      "\n",
      "\n",
      "========================\n",
      "\n",
      "ADV\n",
      "\n",
      "\n",
      "[[[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [1.]\n",
      "   [1.]]]\n",
      "\n",
      "\n",
      " [[[1.]\n",
      "   [1.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [1.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [1.]\n",
      "   [1.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [1.]\n",
      "   [1.]]]\n",
      "\n",
      "\n",
      " [[[1.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]]]\n",
      "==============\n",
      "\n",
      "\n",
      "========================\n",
      "\n",
      "G Predict ADV - PURIFIED\n",
      "\n",
      "\n",
      "[[[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]]\n",
      "==============\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "F = keras.models.load_model('./modelClassifierFGSM.h5')\n",
    "print(\"========================\\n\\nKERAS LOAD MODEL\\n\\n\")\n",
    "print(F.summary())\n",
    "print(\"==============\\n\\n\")\n",
    "\n",
    "clean = X_TEST.copy().reshape(-1,1,X_TEST.shape[1],1)\n",
    "adv = X_N_TEST.copy().reshape(-1,1,X_TEST.shape[1],1)\n",
    "label = Y_TEST.copy()\n",
    "\n",
    "print(\"========================\\n\\nCLEAN\\n\\n\")\n",
    "print(clean)\n",
    "print(\"==============\\n\\n\")\n",
    "\n",
    "print(\"========================\\n\\nADV\\n\\n\")\n",
    "print(adv)\n",
    "print(\"==============\\n\\n\")\n",
    "\n",
    "purified = G.predict(adv)\n",
    "print(\"========================\\n\\nG Predict ADV - PURIFIED\\n\\n\")\n",
    "print(purified)\n",
    "print(\"==============\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3799, 2948)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv.reshape(-1,adv.shape[2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "\n",
      "F Predict ADV\n",
      "\n",
      "\n",
      "[[0.0000000e+00]\n",
      " [0.0000000e+00]\n",
      " [0.0000000e+00]\n",
      " ...\n",
      " [1.3551286e-06]\n",
      " [0.0000000e+00]\n",
      " [0.0000000e+00]]\n",
      "==============\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FPredAdv = F.predict(adv.reshape(-1,adv.shape[2]))\n",
    "print(\"========================\\n\\nF Predict ADV\\n\\n\")\n",
    "print(FPredAdv)\n",
    "print(\"==============\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "\n",
      "F Predict ADV FUNC- ADV_PDT\n",
      "\n",
      "\n",
      "[0 0 0 ... 0 0 0]\n",
      "==============\n",
      "\n",
      "\n",
      "(array([0], dtype=int64), array([3799], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "adv_pdt = np.argmax(FPredAdv, axis=1)\n",
    "print(\"========================\\n\\nF Predict ADV FUNC- ADV_PDT\\n\\n\")\n",
    "print(adv_pdt)\n",
    "print(\"==============\\n\\n\")\n",
    "print(np.unique(adv_pdt,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "\n",
      "F Predict CLEAN\n",
      "\n",
      "\n",
      "[[0.98784703]\n",
      " [0.9990308 ]\n",
      " [0.79184556]\n",
      " ...\n",
      " [0.9997898 ]\n",
      " [0.987847  ]\n",
      " [0.9801514 ]]\n",
      "==============\n",
      "\n",
      "\n",
      "========================\n",
      "\n",
      "F Predict CLEAN FUNC- ADV_PDT\n",
      "\n",
      "\n",
      "[0 0 0 ... 0 0 0]\n",
      "==============\n",
      "\n",
      "\n",
      "(array([0], dtype=int64), array([3799], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "FPredClean = F.predict(clean.reshape(-1,adv.shape[2]))\n",
    "print(\"========================\\n\\nF Predict CLEAN\\n\\n\")\n",
    "print(FPredClean)\n",
    "print(\"==============\\n\\n\")\n",
    "clean_pdt = np.argmax(FPredClean, axis=1)\n",
    "print(\"========================\\n\\nF Predict CLEAN FUNC- ADV_PDT\\n\\n\")\n",
    "print(clean_pdt)\n",
    "print(\"==============\\n\\n\")\n",
    "print(np.unique(clean_pdt,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "\n",
      "F Predict PURIFIED \n",
      "\n",
      "\n",
      "[[0.05129439]\n",
      " [0.05129439]\n",
      " [0.05129439]\n",
      " ...\n",
      " [0.05129439]\n",
      " [0.05129439]\n",
      " [0.05129439]]\n",
      "==============\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FPredPur = F.predict(purified.reshape(-1,adv.shape[2]))\n",
    "print(\"========================\\n\\nF Predict PURIFIED \\n\\n\")\n",
    "print(FPredPur)\n",
    "print(\"==============\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "\n",
      "F Predict PURIFIED FUNC - PURIFIED_PDT\n",
      "\n",
      "\n",
      "[0 0 0 ... 0 0 0]\n",
      "==============\n",
      "\n",
      "\n",
      "(array([0], dtype=int64), array([3799], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "purified_pdt = np.argmax(FPredPur, axis=1)\n",
    "print(\"========================\\n\\nF Predict PURIFIED FUNC - PURIFIED_PDT\\n\\n\")\n",
    "print(purified_pdt)\n",
    "print(\"==============\\n\\n\")\n",
    "print(np.unique(purified_pdt,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "\n",
      "LABEL\n",
      "\n",
      "\n",
      "[1 1 1 ... 1 1 1]\n",
      "==============\n",
      "\n",
      "\n",
      "(array([1]), array([3799], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(\"========================\\n\\nLABEL\\n\\n\")\n",
    "print(label)\n",
    "print(\"==============\\n\\n\")\n",
    "print(np.unique(label,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " adv acc: 0.0000000000,\n",
      " rct acc: 0.0000000000,\n",
      "\n",
      "\n",
      " SIMILARITY: 1.0000000000\n"
     ]
    }
   ],
   "source": [
    "print(' adv acc: {:.10f},\\n rct acc: {:.10f},\\n\\n\\n SIMILARITY: {:.10f}'.format( np.mean(adv_pdt==label), \n",
    "                                    np.mean(purified_pdt==label), np.mean(adv_pdt==purified_pdt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3799/3799 [==============================] - 2s 520us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04282340146973827, 1.0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.evaluate(clean.reshape(-1,2948), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3799/3799 [==============================] - 2s 443us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[299.8835265824091, 0.0]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.evaluate(adv.reshape(-1,2948), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3799/3799 [==============================] - 2s 447us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.970173834310955, 0.0]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.evaluate(purified.reshape(-1,2948), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3799, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FPredAdv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(FPredAdv,bins=2,color='white', edgecolor='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      "nobs\n",
      "3799\n",
      "===========\n",
      "min,max\n",
      "(array([0.], dtype=float32), array([0.4306298], dtype=float32))\n",
      "===========\n",
      "mean\n",
      "[0.00035468]\n",
      "===========\n",
      "var\n",
      "[0.00013957]\n",
      "===========\n",
      "skewness\n",
      "[35.453857]\n",
      "===========\n",
      "kurtosis\n",
      "[1260.1925]\n"
     ]
    }
   ],
   "source": [
    "StatsDesc = ['nobs','min,max','mean','var','skewness','kurtosis']\n",
    "for i in range(len(stats.describe(FPredAdv))):\n",
    "    print(\"===========\")\n",
    "    print(StatsDesc[i])\n",
    "    print(stats.describe(FPredAdv)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.], dtype=float32), array([11199452], dtype=int64))\n",
      "(3799, 1, 2948, 1)\n",
      "11199452 0\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(purified,return_counts=True))\n",
    "print(purified.shape)\n",
    "c = ccc = 0\n",
    "for i in range(len(purified)):\n",
    "    for j in range(purified.shape[2]):\n",
    "        if purified[i][0][j][0]==0:\n",
    "            c+=1\n",
    "        else:\n",
    "            ccc+=1\n",
    "            \n",
    "print(c,ccc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccc/15621"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(FPredPur,bins=2,color='white', edgecolor='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      "nobs\n",
      "3799\n",
      "===========\n",
      "min,max\n",
      "(array([0.05129439], dtype=float32), array([0.05129439], dtype=float32))\n",
      "===========\n",
      "mean\n",
      "[0.05129439]\n",
      "===========\n",
      "var\n",
      "[1.0961918e-20]\n",
      "===========\n",
      "skewness\n",
      "[35.585575]\n",
      "===========\n",
      "kurtosis\n",
      "[1263.3259]\n"
     ]
    }
   ],
   "source": [
    "StatsDesc = ['nobs','min,max','mean','var','skewness','kurtosis']\n",
    "for i in range(len(stats.describe(FPredPur))):\n",
    "    print(\"===========\")\n",
    "    print(StatsDesc[i])\n",
    "    print(stats.describe(FPredPur)[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions FGSM PURE MAL\n",
    "\n",
    "Given that FGSM Pure MAL is also converting all to 0. We were stuck here for quite some time and then began going over to other methods. The next section discusses about those methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
