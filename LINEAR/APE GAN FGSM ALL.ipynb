{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING\n"
     ]
    }
   ],
   "source": [
    "print(\"STARTING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils  # utilities for one-hot encoding of ground truth values\n",
    "\n",
    "import os\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Sequential  # basic class for specifying and training a neural network\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose, Dense, Activation, Flatten, LeakyReLU, BatchNormalization, ZeroPadding2D, Conv1D\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN = np.load('./DATA/ORIGINAL/X_train.npy')\n",
    "Y_TRAIN = np.load('./DATA/ORIGINAL/y_train.npy')\n",
    "X_TEST = np.load('./DATA/FGSM/X_TEST_ORG.npy')\n",
    "Y_TEST = np.load('./DATA/FGSM/Y_TEST_ORG.npy')\n",
    "coeff = np.load('./DATA/ORIGINAL/coeff_features.npy')\n",
    "X_N_TEST = np.load('./DATA/FGSM/X_TEST_NOISED.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Build\n",
    "\n",
    "Building a classifier to evaluate the denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31713, 2948)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_TRAIN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15621, 2) (31713, 1)\n"
     ]
    }
   ],
   "source": [
    "print(Y_TEST.shape,Y_TRAIN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_TEST = Y_TEST[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If Its ben, xTrain is 0, mal means 1.\n",
    "\n",
    "In xTest, ben is 1 0 and mal is 0 1\n",
    "\n",
    "taking the 2nd col, i.e index 1 col will give us  same as XTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([21142, 10571], dtype=int64))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_TRAIN,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassifierModel(inputDims):\n",
    "    modelClassifier = Sequential()\n",
    "\n",
    "    modelClassifier.add(Dense(inputDims, input_dim=inputDims, activation='relu'))\n",
    "\n",
    "    modelClassifier.add(Dense(128, activation='relu'))\n",
    "\n",
    "    modelClassifier.add(Dense(1, activation='sigmoid'))\n",
    "    modelClassifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return modelClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 2948)              8693652   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               377472    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 9,071,253\n",
      "Trainable params: 9,071,253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelClassifier = ClassifierModel(X_TRAIN.shape[1])\n",
    "modelClassifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31713/31713 [==============================] - 43s 1ms/step - loss: 0.1683 - accuracy: 0.9394\n",
      "Epoch 2/5\n",
      "31713/31713 [==============================] - 42s 1ms/step - loss: 0.1053 - accuracy: 0.9647\n",
      "Epoch 3/5\n",
      "31713/31713 [==============================] - 42s 1ms/step - loss: 0.0849 - accuracy: 0.9714\n",
      "Epoch 4/5\n",
      "31713/31713 [==============================] - 44s 1ms/step - loss: 0.0730 - accuracy: 0.9756\n",
      "Epoch 5/5\n",
      "31713/31713 [==============================] - 43s 1ms/step - loss: 0.0632 - accuracy: 0.9781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x185070e9848>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelClassifier.fit(X_TRAIN, Y_TRAIN, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelClassifier = keras.models.load_model('./ResultsNov2/modelClassifierFGSM.h5')\n",
    "# modelClassifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31713/31713 [==============================] - 14s 433us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.058908848948836676, 0.9792198538780212]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelClassifier.evaluate(X_TRAIN, Y_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15621/15621 [==============================] - 7s 428us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13288401077350578, 0.9652391076087952]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelClassifier.evaluate(X_TEST, Y_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15621/15621 [==============================] - 7s 420us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[74.89454516371816, 0.7323474884033203]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelClassifier.evaluate(X_N_TEST, Y_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of classifier\n",
    "\n",
    "- Training data =97.9%\n",
    "- Testing data = 96.5%\n",
    "- FGSM attacked data = 73.2%\n",
    "\n",
    "Drop of almost 23% is good, considering only 33% of the data was malware. Now only around 10% is found to be malware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2948,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weightsmodelClassifier, biasesmodelClassifier = modelClassifier.layers[0].get_weights()\n",
    "modelClassifier.layers[0].get_weights()[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelClassifier.save('modelClassifierFGSM.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ben and Mal Cols and Pure Malware and Benign Arrays\n",
    "\n",
    "Pure Malware = all malware columns will be one\n",
    "\n",
    "Pure Ben = all Ben cols will be one\n",
    "\n",
    "This gives us the 2 extreme cases to compare with one another during GAN training. All Ben being the most benign and all mal being the worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1513 1435\n"
     ]
    }
   ],
   "source": [
    "mal_col_index = []\n",
    "ben_col_index = []\n",
    "for i in range(len(coeff)):\n",
    "    if coeff[i] > 0:\n",
    "        mal_col_index.append(i)\n",
    "    elif coeff[i] < 0:\n",
    "        ben_col_index.append(i)\n",
    "    else:\n",
    "        print(\"DANGER\")\n",
    "print(len(mal_col_index),len(ben_col_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([1513, 1435], dtype=int64))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_BEN_APK = np.zeros(X_TEST[0].shape)\n",
    "for i in ben_col_index:\n",
    "    ALL_BEN_APK[i] = 1\n",
    "np.unique(ALL_BEN_APK,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([1435, 1513], dtype=int64))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_MAL_APK = np.zeros(X_TEST[0].shape)\n",
    "for i in mal_col_index:\n",
    "    ALL_MAL_APK[i] = 1\n",
    "np.unique(ALL_MAL_APK,return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APE GAN DEF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MANHATTAN(y_true, y_pred):\n",
    "    return K.sum( K.abs( y_true - y_pred),axis=1,keepdims=True) + 1e-10\n",
    "\n",
    "def SRMSE(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1) + 1e-10)\n",
    "\n",
    "def WMOD(y_true, y_pred):\n",
    "    return K.abs(1 - K.mean(y_true * y_pred))\n",
    "\n",
    "def WGAN(y_true, y_pred):\n",
    "    return K.abs(K.mean(y_true * y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(input_dims):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape = input_dims, activation='relu'))\n",
    "    #model.add(Dense(2048, input_shape = input_dims, activation='relu'))\n",
    "    #model.add(Dense(1024, activation='relu'))\n",
    "    #model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dense(2, activation='relu'))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.add(Activation('tanh'))\n",
    "    return model\n",
    "\n",
    "def discriminator(input_dims):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape = input_dims, activation='relu'))\n",
    "    #model.add(Dense(2048, input_shape = input_dims, activation='relu'))\n",
    "    #model.add(Dense(1024, activation='relu'))\n",
    "    #model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dense(2, activation='relu'))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    return model\n",
    "\n",
    "def APEGAN(input_dims):\n",
    "    G = generator(input_dims)\n",
    "    print(\"========================\\n\\nGENERATOR\\n\\n\")\n",
    "    print(G.summary())\n",
    "    print(\"==============\\n\\n\")\n",
    "    \n",
    "    D = discriminator(input_dims)\n",
    "    print(\"========================\\n\\nDISCRIMINATOR\\n\\n\")\n",
    "    print(D.summary())\n",
    "    print(\"==============\\n\\n\")\n",
    "    \n",
    "    ipt = Input(input_dims)\n",
    "    print(\"========================\\n\\nINPUT TENSOR\\n\\n\")\n",
    "    print(ipt)\n",
    "    print(\"==============\\n\\n\")\n",
    "    \n",
    "    purified = G(ipt)\n",
    "    print(\"========================\\n\\nPURIFIED TENSOR\\n\\n\")\n",
    "    print(purified)\n",
    "    print(\"==============\\n\\n\")\n",
    "    \n",
    "    D.trainable = False\n",
    "    \n",
    "    judge = D(purified)\n",
    "    print(\"========================\\n\\nJUDGE TENSOR\\n\\n\")\n",
    "    print(judge)\n",
    "    print(\"==============\\n\\n\")\n",
    "    \n",
    "    GAN = Model(ipt, [judge,purified])\n",
    "    print(\"========================\\n\\nGAN BASIC\\n\\n\")\n",
    "    print(GAN.summary())\n",
    "    print(\"==============\\n\\n\")\n",
    "    \n",
    "    GAN.compile(optimizer='adam',\n",
    "                loss=['binary_crossentropy',WGAN],\n",
    "                loss_weights=[0.02, 0.9])\n",
    "    \n",
    "    print(\"========================\\n\\nGAN AFTER COMPILE\\n\\n\")\n",
    "    print(GAN.summary())\n",
    "    print(\"==============\\n\\n\")\n",
    "    \n",
    "    return GAN,G,D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APE GAN RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10 # original 500\n",
    "batch_size=128\n",
    "\n",
    "N = X_TEST.shape[0]\n",
    "x_clean = X_TEST.copy()\n",
    "x_adv = X_N_TEST.copy()\n",
    "x_label = Y_TEST.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "\n",
      "GENERATOR\n",
      "\n",
      "\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 1, 2948, 512)      1024      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1, 2948, 256)      131328    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1, 2948, 128)      32896     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1, 2948, 64)       8256      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1, 2948, 32)       2080      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1, 2948, 16)       528       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1, 2948, 8)        136       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1, 2948, 4)        36        \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1, 2948, 2)        10        \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1, 2948, 1)        3         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1, 2948, 1)        0         \n",
      "=================================================================\n",
      "Total params: 176,297\n",
      "Trainable params: 176,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "==============\n",
      "\n",
      "\n",
      "========================\n",
      "\n",
      "DISCRIMINATOR\n",
      "\n",
      "\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 1, 2948, 512)      1024      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1, 2948, 256)      131328    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1, 2948, 128)      32896     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1, 2948, 64)       8256      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1, 2948, 32)       2080      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1, 2948, 16)       528       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1, 2948, 8)        136       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1, 2948, 4)        36        \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1, 2948, 2)        10        \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1, 2948, 1)        3         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1, 2948, 1)        0         \n",
      "=================================================================\n",
      "Total params: 176,297\n",
      "Trainable params: 176,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "==============\n",
      "\n",
      "\n",
      "========================\n",
      "\n",
      "INPUT TENSOR\n",
      "\n",
      "\n",
      "Tensor(\"input_1:0\", shape=(?, 1, 2948, 1), dtype=float32)\n",
      "==============\n",
      "\n",
      "\n",
      "========================\n",
      "\n",
      "PURIFIED TENSOR\n",
      "\n",
      "\n",
      "Tensor(\"sequential_4/activation_1/Tanh:0\", shape=(?, 1, 2948, 1), dtype=float32)\n",
      "==============\n",
      "\n",
      "\n",
      "========================\n",
      "\n",
      "JUDGE TENSOR\n",
      "\n",
      "\n",
      "Tensor(\"sequential_5/activation_2/Sigmoid:0\", shape=(?, 1, 2948, 1), dtype=float32)\n",
      "==============\n",
      "\n",
      "\n",
      "========================\n",
      "\n",
      "GAN BASIC\n",
      "\n",
      "\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1, 2948, 1)        0         \n",
      "_________________________________________________________________\n",
      "sequential_4 (Sequential)    (None, 1, 2948, 1)        176297    \n",
      "_________________________________________________________________\n",
      "sequential_5 (Sequential)    (None, 1, 2948, 1)        176297    \n",
      "=================================================================\n",
      "Total params: 352,594\n",
      "Trainable params: 176,297\n",
      "Non-trainable params: 176,297\n",
      "_________________________________________________________________\n",
      "None\n",
      "==============\n",
      "\n",
      "\n",
      "========================\n",
      "\n",
      "GAN AFTER COMPILE\n",
      "\n",
      "\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1, 2948, 1)        0         \n",
      "_________________________________________________________________\n",
      "sequential_4 (Sequential)    (None, 1, 2948, 1)        176297    \n",
      "_________________________________________________________________\n",
      "sequential_5 (Sequential)    (None, 1, 2948, 1)        176297    \n",
      "=================================================================\n",
      "Total params: 352,594\n",
      "Trainable params: 176,297\n",
      "Non-trainable params: 176,297\n",
      "_________________________________________________________________\n",
      "None\n",
      "==============\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GAN, G, D = APEGAN([1,X_TEST.shape[1],1])\n",
    "# GAN,G,D = APEGAN([X_TEST.shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "EPOCH 0 \n",
      "\n",
      "\n",
      "=====\n",
      "SHAPE of XCLEAN\n",
      "(128, 1, 2948, 1)\n",
      "\n",
      "=====\n",
      "NP ONES TRAIN ON BATCH DISCRIMINATOR\n",
      "1 [0.34657296538352966, 0, 0]\n",
      "\n",
      "=====\n",
      "NP ZEROS TRAIN ON BATCH DISCRIMINATOR\n",
      "2 [0.6931459307670593, 0, 0]\n",
      "\n",
      "=====\n",
      "LOSS HISTORY\n",
      "[[0.6931459307670593, 0.69314593, 0.0], 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "=====\n",
      "TRAIN ON BATCH GAN\n",
      "Epoch number: 0 ; Loss [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      " EPOCHING \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "EPOCH 1 \n",
      "\n",
      "\n",
      "=====\n",
      "SHAPE of XCLEAN\n",
      "(128, 1, 2948, 1)\n",
      "\n",
      "=====\n",
      "NP ONES TRAIN ON BATCH DISCRIMINATOR\n",
      "1 [0.34657296538352966, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "NP ZEROS TRAIN ON BATCH DISCRIMINATOR\n",
      "2 [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "LOSS HISTORY\n",
      "[[0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "=====\n",
      "TRAIN ON BATCH GAN\n",
      "Epoch number: 1 ; Loss [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      " EPOCHING \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "EPOCH 2 \n",
      "\n",
      "\n",
      "=====\n",
      "SHAPE of XCLEAN\n",
      "(128, 1, 2948, 1)\n",
      "\n",
      "=====\n",
      "NP ONES TRAIN ON BATCH DISCRIMINATOR\n",
      "1 [0.34657296538352966, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "NP ZEROS TRAIN ON BATCH DISCRIMINATOR\n",
      "2 [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "LOSS HISTORY\n",
      "[[0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "=====\n",
      "TRAIN ON BATCH GAN\n",
      "Epoch number: 2 ; Loss [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      " EPOCHING \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "EPOCH 3 \n",
      "\n",
      "\n",
      "=====\n",
      "SHAPE of XCLEAN\n",
      "(128, 1, 2948, 1)\n",
      "\n",
      "=====\n",
      "NP ONES TRAIN ON BATCH DISCRIMINATOR\n",
      "1 [0.34657296538352966, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "NP ZEROS TRAIN ON BATCH DISCRIMINATOR\n",
      "2 [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "LOSS HISTORY\n",
      "[[0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "=====\n",
      "TRAIN ON BATCH GAN\n",
      "Epoch number: 3 ; Loss [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      " EPOCHING \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "EPOCH 4 \n",
      "\n",
      "\n",
      "=====\n",
      "SHAPE of XCLEAN\n",
      "(128, 1, 2948, 1)\n",
      "\n",
      "=====\n",
      "NP ONES TRAIN ON BATCH DISCRIMINATOR\n",
      "1 [0.34657296538352966, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "NP ZEROS TRAIN ON BATCH DISCRIMINATOR\n",
      "2 [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "LOSS HISTORY\n",
      "[[0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], 0, 0, 0, 0, 0]\n",
      "\n",
      "=====\n",
      "TRAIN ON BATCH GAN\n",
      "Epoch number: 4 ; Loss [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      " EPOCHING \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "EPOCH 5 \n",
      "\n",
      "\n",
      "=====\n",
      "SHAPE of XCLEAN\n",
      "(128, 1, 2948, 1)\n",
      "\n",
      "=====\n",
      "NP ONES TRAIN ON BATCH DISCRIMINATOR\n",
      "1 [0.34657296538352966, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "NP ZEROS TRAIN ON BATCH DISCRIMINATOR\n",
      "2 [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "LOSS HISTORY\n",
      "[[0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], 0, 0, 0, 0]\n",
      "\n",
      "=====\n",
      "TRAIN ON BATCH GAN\n",
      "Epoch number: 5 ; Loss [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      " EPOCHING \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "EPOCH 6 \n",
      "\n",
      "\n",
      "=====\n",
      "SHAPE of XCLEAN\n",
      "(128, 1, 2948, 1)\n",
      "\n",
      "=====\n",
      "NP ONES TRAIN ON BATCH DISCRIMINATOR\n",
      "1 [0.34657296538352966, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "NP ZEROS TRAIN ON BATCH DISCRIMINATOR\n",
      "2 [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "LOSS HISTORY\n",
      "[[0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], 0, 0, 0]\n",
      "\n",
      "=====\n",
      "TRAIN ON BATCH GAN\n",
      "Epoch number: 6 ; Loss [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      " EPOCHING \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "EPOCH 7 \n",
      "\n",
      "\n",
      "=====\n",
      "SHAPE of XCLEAN\n",
      "(128, 1, 2948, 1)\n",
      "\n",
      "=====\n",
      "NP ONES TRAIN ON BATCH DISCRIMINATOR\n",
      "1 [0.34657296538352966, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "NP ZEROS TRAIN ON BATCH DISCRIMINATOR\n",
      "2 [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "LOSS HISTORY\n",
      "[[0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], 0, 0]\n",
      "\n",
      "=====\n",
      "TRAIN ON BATCH GAN\n",
      "Epoch number: 7 ; Loss [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      " EPOCHING \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "EPOCH 8 \n",
      "\n",
      "\n",
      "=====\n",
      "SHAPE of XCLEAN\n",
      "(128, 1, 2948, 1)\n",
      "\n",
      "=====\n",
      "NP ONES TRAIN ON BATCH DISCRIMINATOR\n",
      "1 [0.34657296538352966, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "NP ZEROS TRAIN ON BATCH DISCRIMINATOR\n",
      "2 [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "LOSS HISTORY\n",
      "[[0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], 0]\n",
      "\n",
      "=====\n",
      "TRAIN ON BATCH GAN\n",
      "Epoch number: 8 ; Loss [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      " EPOCHING \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "EPOCH 9 \n",
      "\n",
      "\n",
      "=====\n",
      "SHAPE of XCLEAN\n",
      "(128, 1, 2948, 1)\n",
      "\n",
      "=====\n",
      "NP ONES TRAIN ON BATCH DISCRIMINATOR\n",
      "1 [0.34657296538352966, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "NP ZEROS TRAIN ON BATCH DISCRIMINATOR\n",
      "2 [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      "=====\n",
      "LOSS HISTORY\n",
      "[[0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0], [0.6931459307670593, 0.69314593, 0.0]]\n",
      "\n",
      "=====\n",
      "TRAIN ON BATCH GAN\n",
      "Epoch number: 9 ; Loss [0.6931459307670593, 0.69314593, 0.0]\n",
      "\n",
      " EPOCHING \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================\n",
      "SCALAR LOSS HISTORY\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scalarloss = [0,0,0]\n",
    "LossHistory = [0]*epochs\n",
    "for cur_epoch in range(epochs):\n",
    "    \n",
    "    print(\"\\n\\nEPOCH\",cur_epoch,\"\\n\")\n",
    "    \n",
    "    idx = np.random.randint(0, N*4//5, size=batch_size)\n",
    "    x_clean_batch = x_clean[idx,].reshape(-1,1,2948,1)\n",
    "    x_adv_batch = x_adv[idx,].reshape(-1,1,2948,1)\n",
    "    \n",
    "    ALL_MAL_APK_BATCH = np.tile(ALL_MAL_APK,(batch_size,1))\n",
    "    ALL_BEN_APK_BATCH = np.tile(ALL_BEN_APK,(batch_size,1))    \n",
    "    \n",
    "    print(\"\\n=====\\nSHAPE of XCLEAN\")\n",
    "    print(x_clean_batch.shape)\n",
    "    \n",
    "    scalarloss[0] = D.train_on_batch(x_clean_batch, ALL_MAL_APK_BATCH.reshape(-1,1,2948,1))/2\n",
    "    \n",
    "    print(\"\\n=====\\nNP ONES TRAIN ON BATCH DISCRIMINATOR\")\n",
    "    print(\"1 \"+str(scalarloss))\n",
    "    \n",
    "    scalarloss[0] += D.train_on_batch(x_adv_batch, ALL_BEN_APK_BATCH.reshape(-1,1,2948,1))/2\n",
    "    \n",
    "    print(\"\\n=====\\nNP ZEROS TRAIN ON BATCH DISCRIMINATOR\")\n",
    "    print(\"2 \"+str(scalarloss))\n",
    "    \n",
    "    GAN.train_on_batch(x_adv_batch, [ ALL_MAL_APK_BATCH.reshape(-1,1,2948,1), x_clean_batch])\n",
    "    \n",
    "    scalarloss[1:] = GAN.train_on_batch(x_adv_batch, [ ALL_MAL_APK_BATCH.reshape(-1,1,2948,1), x_clean_batch])[1:]\n",
    "    \n",
    "#     LossHistory.append(scalarloss)\n",
    "    LossHistory[cur_epoch] = scalarloss\n",
    "    print(\"\\n=====\\nLOSS HISTORY\")\n",
    "    print(LossHistory)\n",
    "    \n",
    "    print(\"\\n=====\\nTRAIN ON BATCH GAN\")\n",
    "    print(\"Epoch number:\",cur_epoch,\"; Loss\",scalarloss)\n",
    "    print(\"\\n EPOCHING \\n\\n\\n\\n\\n\")\n",
    "print(\"\\n\\n\\n\\n=============================\\nSCALAR LOSS HISTORY\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "We use the Generator of the trained APEGAN to purify data samples and then test it out with the trained classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "\n",
      "KERAS LOAD MODEL\n",
      "\n",
      "\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 2948)              8693652   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               377472    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 9,071,253\n",
      "Trainable params: 9,071,253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "==============\n",
      "\n",
      "\n",
      "========================\n",
      "\n",
      "CLEAN\n",
      "\n",
      "\n",
      "[[[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]]\n",
      "==============\n",
      "\n",
      "\n",
      "========================\n",
      "\n",
      "ADV\n",
      "\n",
      "\n",
      "[[[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [1.]\n",
      "   [1.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[1.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]]\n",
      "==============\n",
      "\n",
      "\n",
      "========================\n",
      "\n",
      "G Predict ADV - PURIFIED\n",
      "\n",
      "\n",
      "[[[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]]\n",
      "==============\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "F = keras.models.load_model('./modelClassifierFGSM.h5')\n",
    "print(\"========================\\n\\nKERAS LOAD MODEL\\n\\n\")\n",
    "print(F.summary())\n",
    "print(\"==============\\n\\n\")\n",
    "\n",
    "clean = X_TEST.copy().reshape(-1,1,X_TEST.shape[1],1)\n",
    "adv = X_N_TEST.copy().reshape(-1,1,X_TEST.shape[1],1)\n",
    "label = Y_TEST.copy()\n",
    "\n",
    "print(\"========================\\n\\nCLEAN\\n\\n\")\n",
    "print(clean)\n",
    "print(\"==============\\n\\n\")\n",
    "\n",
    "print(\"========================\\n\\nADV\\n\\n\")\n",
    "print(adv)\n",
    "print(\"==============\\n\\n\")\n",
    "\n",
    "purified = G.predict(adv)\n",
    "print(\"========================\\n\\nG Predict ADV - PURIFIED\\n\\n\")\n",
    "print(purified)\n",
    "print(\"==============\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15621, 2948)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv.reshape(-1,adv.shape[2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "\n",
      "F Predict ADV\n",
      "\n",
      "\n",
      "[[1.7094612e-04]\n",
      " [5.9604645e-08]\n",
      " [0.0000000e+00]\n",
      " ...\n",
      " [7.3462427e-03]\n",
      " [0.0000000e+00]\n",
      " [2.5811319e-06]]\n",
      "==============\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FPredAdv = F.predict(adv.reshape(-1,adv.shape[2]))\n",
    "print(\"========================\\n\\nF Predict ADV\\n\\n\")\n",
    "print(FPredAdv)\n",
    "print(\"==============\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "\n",
      "F Predict ADV FUNC- ADV_PDT\n",
      "\n",
      "\n",
      "[0 0 0 ... 0 0 0]\n",
      "==============\n",
      "\n",
      "\n",
      "(array([0], dtype=int64), array([15621], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "adv_pdt = np.argmax(FPredAdv, axis=1)\n",
    "print(\"========================\\n\\nF Predict ADV FUNC- ADV_PDT\\n\\n\")\n",
    "print(adv_pdt)\n",
    "print(\"==============\\n\\n\")\n",
    "print(np.unique(adv_pdt,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "\n",
      "F Predict CLEAN\n",
      "\n",
      "\n",
      "[[1.7094612e-04]\n",
      " [5.9604645e-08]\n",
      " [9.8784703e-01]\n",
      " ...\n",
      " [7.3462427e-03]\n",
      " [9.8015136e-01]\n",
      " [2.5811319e-06]]\n",
      "==============\n",
      "\n",
      "\n",
      "========================\n",
      "\n",
      "F Predict CLEAN FUNC- ADV_PDT\n",
      "\n",
      "\n",
      "[0 0 0 ... 0 0 0]\n",
      "==============\n",
      "\n",
      "\n",
      "(array([0], dtype=int64), array([15621], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "FPredClean = F.predict(clean.reshape(-1,adv.shape[2]))\n",
    "print(\"========================\\n\\nF Predict CLEAN\\n\\n\")\n",
    "print(FPredClean)\n",
    "print(\"==============\\n\\n\")\n",
    "clean_pdt = np.argmax(FPredClean, axis=1)\n",
    "print(\"========================\\n\\nF Predict CLEAN FUNC- ADV_PDT\\n\\n\")\n",
    "print(clean_pdt)\n",
    "print(\"==============\\n\\n\")\n",
    "print(np.unique(clean_pdt,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "\n",
      "F Predict PURIFIED \n",
      "\n",
      "\n",
      "[[0.05129439]\n",
      " [0.05129439]\n",
      " [0.05129439]\n",
      " ...\n",
      " [0.05129439]\n",
      " [0.05129439]\n",
      " [0.05129439]]\n",
      "==============\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FPredPur = F.predict(purified.reshape(-1,adv.shape[2]))\n",
    "print(\"========================\\n\\nF Predict PURIFIED \\n\\n\")\n",
    "print(FPredPur)\n",
    "print(\"==============\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "\n",
      "F Predict PURIFIED FUNC - PURIFIED_PDT\n",
      "\n",
      "\n",
      "[0 0 0 ... 0 0 0]\n",
      "==============\n",
      "\n",
      "\n",
      "(array([0], dtype=int64), array([15621], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "purified_pdt = np.argmax(FPredPur, axis=1)\n",
    "print(\"========================\\n\\nF Predict PURIFIED FUNC - PURIFIED_PDT\\n\\n\")\n",
    "print(purified_pdt)\n",
    "print(\"==============\\n\\n\")\n",
    "print(np.unique(purified_pdt,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "\n",
      "LABEL\n",
      "\n",
      "\n",
      "[0. 0. 1. ... 0. 1. 0.]\n",
      "==============\n",
      "\n",
      "\n",
      "(array([0., 1.]), array([10414,  5207], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(\"========================\\n\\nLABEL\\n\\n\")\n",
    "print(label)\n",
    "print(\"==============\\n\\n\")\n",
    "print(np.unique(label,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " adv acc: 0.6666666667,\n",
      " rct acc: 0.6666666667,\n",
      "\n",
      "\n",
      " SIMILARITY: 1.0000000000\n"
     ]
    }
   ],
   "source": [
    "print(' adv acc: {:.10f},\\n rct acc: {:.10f},\\n\\n\\n SIMILARITY: {:.10f}'.format( np.mean(adv_pdt==label), \n",
    "                                    np.mean(purified_pdt==label), np.mean(adv_pdt==purified_pdt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15621/15621 [==============================] - 7s 454us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13288401077350578, 0.9652391076087952]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.evaluate(clean.reshape(-1,2948), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15621/15621 [==============================] - 7s 443us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[74.89454516371816, 0.7323474884033203]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.evaluate(adv.reshape(-1,2948), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15621/15621 [==============================] - 7s 441us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.025162445576241, 0.6666666865348816]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.evaluate(purified.reshape(-1,2948), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15621, 1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FPredAdv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(FPredAdv,bins=2,color='white', edgecolor='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      "nobs\n",
      "15621\n",
      "===========\n",
      "min,max\n",
      "(array([0.], dtype=float32), array([1.], dtype=float32))\n",
      "===========\n",
      "mean\n",
      "[0.10330237]\n",
      "===========\n",
      "var\n",
      "[0.08514675]\n",
      "===========\n",
      "skewness\n",
      "[2.6368554]\n",
      "===========\n",
      "kurtosis\n",
      "[5.1043234]\n"
     ]
    }
   ],
   "source": [
    "StatsDesc = ['nobs','min,max','mean','var','skewness','kurtosis']\n",
    "for i in range(len(stats.describe(FPredAdv))):\n",
    "    print(\"===========\")\n",
    "    print(StatsDesc[i])\n",
    "    print(stats.describe(FPredAdv)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.], dtype=float32), array([46050708], dtype=int64))\n",
      "(15621, 1, 2948, 1)\n",
      "46050708 0\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(purified,return_counts=True))\n",
    "print(purified.shape)\n",
    "c = ccc = 0\n",
    "for i in range(len(purified)):\n",
    "    for j in range(purified.shape[2]):\n",
    "        if purified[i][0][j][0]==0:\n",
    "            c+=1\n",
    "        else:\n",
    "            ccc+=1\n",
    "            \n",
    "print(c,ccc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccc/15621"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(FPredPur,bins=2,color='white', edgecolor='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      "nobs\n",
      "15621\n",
      "===========\n",
      "min,max\n",
      "(array([0.05129439], dtype=float32), array([0.05129439], dtype=float32))\n",
      "===========\n",
      "mean\n",
      "[0.05129439]\n",
      "===========\n",
      "var\n",
      "[8.884628e-22]\n",
      "===========\n",
      "skewness\n",
      "[124.98399]\n",
      "===========\n",
      "kurtosis\n",
      "[15624.611]\n"
     ]
    }
   ],
   "source": [
    "StatsDesc = ['nobs','min,max','mean','var','skewness','kurtosis']\n",
    "for i in range(len(stats.describe(FPredPur))):\n",
    "    print(\"===========\")\n",
    "    print(StatsDesc[i])\n",
    "    print(stats.describe(FPredPur)[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions FGSM ALL\n",
    "\n",
    "Even though this is done ust for FGSM and with Wasserstein Loss alone, We can see that it converts the whole array to 0. This was the same/almost same case with other loss functions too. With the GAN deciding that converting arrays to all 0 will mean that it is right atleast 67% of the time so it goes that way. \n",
    "\n",
    "JSMA was no different in this matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
